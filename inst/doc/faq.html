<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Chen Yang" />

<meta name="date" content="2026-02-07" />

<title>Frequently Asked Questions</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Frequently Asked Questions</h1>
<h4 class="author">Chen Yang</h4>
<h4 class="date">2026-02-07</h4>



<div id="frequently-asked-questions" class="section level1">
<h1>Frequently Asked Questions</h1>
<p>This document addresses common questions about using mLLMCelltype for
cell type annotation in single-cell RNA sequencing data.</p>
<div id="general-questions" class="section level2">
<h2>General Questions</h2>
<div id="what-makes-mllmcelltype-different-from-other-cell-type-annotation-tools" class="section level3">
<h3>What makes mLLMCelltype different from other cell type annotation
tools?</h3>
<p>mLLMCelltype differs from traditional cell type annotation tools in
several key ways:</p>
<ol style="list-style-type: decimal">
<li><p><strong>No reference dataset required</strong>: Unlike
reference-based methods, mLLMCelltype doesn’t require a pre-existing
reference dataset.</p></li>
<li><p><strong>Multi-model consensus</strong>: mLLMCelltype leverages
multiple large language models to achieve more reliable annotations than
any single model could provide.</p></li>
<li><p><strong>Transparent reasoning</strong>: The package provides
complete reasoning chains for annotations, making the process
interpretable and transparent.</p></li>
<li><p><strong>Uncertainty quantification</strong>: mLLMCelltype
provides explicit uncertainty metrics (consensus proportion and Shannon
entropy) to identify ambiguous cell populations.</p></li>
<li><p><strong>Structured deliberation</strong>: For controversial
clusters, mLLMCelltype initiates a structured discussion process among
models to reach a more reliable consensus.</p></li>
</ol>
</div>
<div id="which-tissues-and-species-does-mllmcelltype-support" class="section level3">
<h3>Which tissues and species does mLLMCelltype support?</h3>
<p>mLLMCelltype can annotate cell types from virtually any tissue and
species, as it relies on the biological knowledge embedded in large
language models rather than pre-defined reference datasets. However,
performance may vary depending on how well-characterized the tissue is
in the scientific literature.</p>
<p>The package has been extensively tested on: - Human tissues (PBMC,
bone marrow, brain, lung, liver, kidney, etc.) - Mouse tissues (brain,
lung, kidney, etc.) - Other model organisms (zebrafish, fruit fly,
etc.)</p>
<p>For very specialized or poorly characterized tissues, the uncertainty
metrics will help identify clusters that may require expert review.</p>
</div>
<div id="how-accurate-is-mllmcelltype-compared-to-other-methods" class="section level3">
<h3>How accurate is mLLMCelltype compared to other methods?</h3>
<p>In our benchmarks (Yang et al., 2025; see our <a href="https://doi.org/10.1101/2025.04.10.647852">paper</a>), the
consensus approach showed improvements over both traditional annotation
methods and single-LLM approaches:</p>
<ul>
<li>Compared to reference-based methods (e.g., SingleR, Seurat label
transfer), mLLMCelltype showed comparable or better performance without
requiring a reference dataset.</li>
<li>Compared to marker-based methods (e.g., SCINA, CellAssign),
mLLMCelltype demonstrated higher accuracy and flexibility.</li>
<li>Compared to single-LLM approaches, the consensus mechanism showed
accuracy improvements on tested datasets.</li>
</ul>
<p>The accuracy advantage is particularly pronounced for rare cell types
and tissues with limited reference data.</p>
</div>
</div>
<div id="technical-questions" class="section level2">
<h2>Technical Questions</h2>
<div id="how-does-mllmcelltype-handle-cluster-indices" class="section level3">
<h3>How does mLLMCelltype handle cluster indices?</h3>
<p>mLLMCelltype preserves your original cluster IDs as-is. Whether your
clusters are numbered 0, 1, 2 (Seurat default) or 1, 2, 3 (R
convention), or use custom names like “t_cells”, the package will use
them directly without modification. The returned annotations use the
same cluster IDs as your input.</p>
</div>
<div id="what-is-the-recommended-number-of-marker-genes-per-cluster" class="section level3">
<h3>What is the recommended number of marker genes per cluster?</h3>
<p>The default setting uses the top 10 marker genes per cluster, which
works well for most scenarios. However, you can adjust this using the
<code>top_gene_count</code> parameter:</p>
<ul>
<li>For well-characterized cell types: 5-10 marker genes is usually
sufficient</li>
<li>For rare or poorly characterized cell types: 10-20 marker genes may
be beneficial</li>
<li>For noisy data: Fewer genes (5-7) might give better results by
focusing on the strongest signals</li>
</ul>
<p>The optimal number depends on the quality of your marker genes and
the complexity of the tissue. We recommend starting with the default of
10 and adjusting based on the results.</p>
</div>
<div id="how-does-caching-work-in-mllmcelltype" class="section level3">
<h3>How does caching work in mLLMCelltype?</h3>
<p>mLLMCelltype implements a caching system to avoid redundant API
calls, which saves time and reduces costs:</p>
<ul>
<li>By default, caching is enabled (<code>cache = TRUE</code>)</li>
<li>The cache is based on a hash of the input data, model, and other
parameters</li>
<li>Results are stored in a local directory (default: a temporary
directory)</li>
<li>You can specify a custom cache directory using the
<code>cache_dir</code> parameter</li>
</ul>
<p>To clear the cache:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>cache_manager <span class="ot">&lt;-</span> CacheManager<span class="sc">$</span><span class="fu">new</span>()</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>cache_manager<span class="sc">$</span><span class="fu">clear_cache</span>()</span></code></pre></div>
<p>Note: The <code>annotate_cell_types</code> function does not have
built-in caching. If you need caching, you’ll need to implement it
separately.</p>
</div>
<div id="how-does-mllmcelltype-handle-rate-limits-and-api-errors" class="section level3">
<h3>How does mLLMCelltype handle rate limits and API errors?</h3>
<p>The package includes error handling for API calls:</p>
<ul>
<li>Detailed error messages: When an API call fails, the error message
includes details to help diagnose the issue</li>
</ul>
<p>If you’re processing many clusters, you might encounter rate limits.
In this case:</p>
<ol style="list-style-type: decimal">
<li>Reduce the number of models used for initial annotation</li>
<li>Process batches of clusters separately with pauses between
batches</li>
<li>Consider implementing your own retry mechanism if needed</li>
</ol>
</div>
</div>
<div id="performance-and-optimization" class="section level2">
<h2>Performance and Optimization</h2>
<div id="how-long-does-it-take-to-run-mllmcelltype" class="section level3">
<h3>How long does it take to run mLLMCelltype?</h3>
<p>The runtime depends on several factors:</p>
<ul>
<li><strong>Number of clusters</strong>: Each cluster requires separate
API calls</li>
<li><strong>Number of models</strong>: More models means more API
calls</li>
<li><strong>Discussion process</strong>: Controversial clusters require
additional API calls for discussion</li>
<li><strong>API response times</strong>: Different providers have
different response times</li>
<li><strong>Network conditions</strong>: Internet speed and reliability
affect performance</li>
</ul>
<p>Typical runtimes: - Single model, 10 clusters: 1-2 minutes -
Multi-model consensus (3 models), 10 clusters: 3-5 minutes - Multi-model
consensus with discussion, 10 clusters: 5-10 minutes</p>
<p>To optimize runtime: - Implement your own caching mechanism if needed
- Start with fewer models for initial exploration - Use a higher
<code>controversy_threshold</code> to reduce the number of controversial
clusters - Process large datasets in batches</p>
</div>
<div id="what-are-the-api-costs-associated-with-using-mllmcelltype" class="section level3">
<h3>What are the API costs associated with using mLLMCelltype?</h3>
<p>The API costs depend on the models you use and the number of
clusters:</p>
<ul>
<li><strong>OpenAI models</strong> (GPT-4o, etc.): $0.01-0.05 per
cluster for annotation</li>
<li><strong>Anthropic models</strong> (Claude 3.7, etc.): $0.01-0.03 per
cluster for annotation</li>
<li><strong>Google models</strong> (Gemini 1.5, etc.): $0.001-0.01 per
cluster for annotation</li>
<li><strong>Other models</strong>: Generally lower cost</li>
<li><strong>OpenRouter free models</strong>: $0.00 (free with
<code>:free</code> suffix)</li>
</ul>
<p>For a typical dataset with 10-20 clusters: - Single model annotation:
$0.10-1.00 total - Multi-model consensus (3 models): $0.30-3.00 total -
With discussion process: Additional $0.10-1.00 - Using OpenRouter free
models: $0.00 total</p>
<p>To reduce costs: - Implement your own caching mechanism to avoid
redundant API calls - Start with more economical models - Use fewer
models for initial exploration - Reserve multi-model consensus for final
analysis - Consider using OpenRouter free models (see below)</p>
</div>
<div id="how-can-i-use-openrouter-free-models" class="section level3">
<h3>How can I use OpenRouter free models?</h3>
<p>OpenRouter provides access to several high-quality models for
free:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Sign up for an OpenRouter account</strong> at <a href="https://openrouter.ai/keys">openrouter.ai</a></p></li>
<li><p><strong>Get your API key</strong> from the OpenRouter
dashboard</p></li>
<li><p><strong>Use models with the <code>:free</code>
suffix</strong>:</p></li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Set your OpenRouter API key</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">OPENROUTER_API_KEY =</span> <span class="st">&quot;your-openrouter-api-key&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Use a free model</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">annotate_cell_types</span>(</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>  <span class="at">input =</span> marker_data,</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>  <span class="at">tissue_name =</span> <span class="st">&quot;human PBMC&quot;</span>,</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">&quot;meta-llama/llama-4-maverick:free&quot;</span>,  <span class="co"># Note the :free suffix</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>  <span class="at">api_key =</span> <span class="fu">Sys.getenv</span>(<span class="st">&quot;OPENROUTER_API_KEY&quot;</span>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>  <span class="co"># No need to specify provider - it&#39;s automatically detected from the model name format</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Recommended free models</strong> (Updated Oct 2025):
<ul>
<li><code>meta-llama/llama-4-maverick:free</code> - Meta Llama 4
Maverick (256K context, best performance)</li>
<li><code>deepseek/deepseek-r1:free</code> - DeepSeek R1 (advanced
reasoning)</li>
<li><code>meta-llama/llama-3.3-70b-instruct:free</code> - Meta Llama 3.3
70B (reliable)</li>
<li><code>venice/uncensored:free</code> - Venice Uncensored (new
model)</li>
<li><code>minimax/minimax-m2:free</code> - MiniMax M2 (optimized for
coding)</li>
<li><code>z-ai/glm-4.5-air:free</code> - GLM 4.5 Air (lightweight)</li>
</ul></li>
</ol>
<p><strong>Important Notes about Free Models</strong> (Updated Oct
2025): - <strong>Daily limits reduced</strong>: 50 requests/day for free
accounts (down from 200) - <strong>Accounts with $10+ credits</strong>:
1000 requests/day - <strong>Rate limit</strong>: 20 requests/minute for
all accounts - <strong>Some models removed</strong>: NVIDIA Nemotron and
others have exited the free tier - <strong>Availability may
change</strong>: Verify current free models at <a href="https://openrouter.ai/models?q=free" class="uri">https://openrouter.ai/models?q=free</a> - <strong>For
production use</strong>: Consider using paid models for better
reliability</p>
</div>
<div id="how-can-i-improve-the-accuracy-of-annotations" class="section level3">
<h3>How can I improve the accuracy of annotations?</h3>
<p>To get the most accurate annotations:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Use multiple high-quality models</strong>: Include
diverse, high-performing models like Claude 3.7, GPT-4o, and Gemini
1.5</p></li>
<li><p><strong>Provide good marker genes</strong>: Use robust
differential expression analysis to identify strong marker
genes</p></li>
<li><p><strong>Specify the correct tissue</strong>: Always provide the
correct tissue name to give models the proper context</p></li>
<li><p><strong>Review uncertainty metrics</strong>: Pay attention to
consensus proportion and Shannon entropy to identify clusters that may
need manual review</p></li>
<li><p><strong>Examine discussion logs</strong>: For controversial
clusters, review the discussion logs to understand the
reasoning</p></li>
<li><p><strong>Iterate if needed</strong>: If results are
unsatisfactory, try adjusting parameters or providing additional
context</p></li>
</ol>
</div>
</div>
<div id="troubleshooting" class="section level2">
<h2>Troubleshooting</h2>
<div id="why-am-i-getting-different-results-with-the-same-input" class="section level3">
<h3>Why am I getting different results with the same input?</h3>
<p>There are several possible reasons for getting different results with
the same input:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Model updates</strong>: LLMs are regularly updated, which
can change their outputs</p></li>
<li><p><strong>Temperature/sampling</strong>: Some randomness is
inherent in LLM outputs</p></li>
<li><p><strong>Context window limitations</strong>: Different runs might
include slightly different context</p></li>
<li><p><strong>API changes</strong>: Providers may change how their APIs
work</p></li>
</ol>
<p>To ensure reproducibility: - Implement your own caching mechanism to
reuse results - Specify model versions explicitly when available - Save
and document your results - Consider saving the raw API responses for
future reference</p>
</div>
<div id="im-getting-an-error-about-invalid-cluster-indices.-what-should-i-do" class="section level3">
<h3>I’m getting an error about invalid cluster indices. What should I
do?</h3>
<p>If you see an error about invalid cluster indices, check that your
cluster column contains valid values. mLLMCelltype accepts any cluster
IDs (numeric or character) and preserves them as-is. Common issues:</p>
<ol style="list-style-type: decimal">
<li>Ensure the <code>cluster</code> column exists in your data
frame</li>
<li>Check for <code>NA</code> values in the cluster column</li>
<li>If using non-standard column names, rename to <code>cluster</code>
before calling the function</li>
</ol>
</div>
<div id="how-do-i-handle-api-key-not-found-errors" class="section level3">
<h3>How do I handle “API key not found” errors?</h3>
<p>If you get an error about missing API keys:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Check environment variables</strong>: Ensure your API
keys are set correctly in your <code>.env</code> file or
environment</p></li>
<li><p><strong>Provide keys directly</strong>: Pass the API key directly
to the function:</p></li>
</ol>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">annotate_cell_types</span>(..., <span class="at">api_key =</span> <span class="st">&quot;your-api-key&quot;</span>)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Check provider name</strong>: Make sure you’re using the
correct provider name for your API key:</li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Set API key for a specific provider</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="fu">Sys.setenv</span>(<span class="at">ANTHROPIC_API_KEY =</span> <span class="st">&quot;your-anthropic-key&quot;</span>)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><strong>Verify key validity</strong>: Check if your API key is still
valid by testing it directly with the provider’s API</li>
</ol>
</div>
<div id="why-are-some-cell-types-not-being-correctly-identified" class="section level3">
<h3>Why are some cell types not being correctly identified?</h3>
<p>If specific cell types are not being correctly identified:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Check marker genes</strong>: Ensure the marker genes for
these cell types are strong and specific</p></li>
<li><p><strong>Provide more context</strong>: Specify the tissue type
accurately to give models the right context</p></li>
<li><p><strong>Use more models</strong>: Different models have different
strengths; using multiple models improves coverage</p></li>
<li><p><strong>Increase marker count</strong>: Try increasing
<code>top_gene_count</code> to include more marker genes</p></li>
<li><p><strong>Review discussion logs</strong>: For controversial
clusters, examine the discussion to understand the reasoning</p></li>
<li><p><strong>Consider rare cell types</strong>: Some cell types may be
poorly represented in the training data of LLMs</p></li>
</ol>
</div>
</div>
<div id="integration-with-other-tools" class="section level2">
<h2>Integration with Other Tools</h2>
<div id="how-does-mllmcelltype-integrate-with-seurat" class="section level3">
<h3>How does mLLMCelltype integrate with Seurat?</h3>
<p>mLLMCelltype integrates with Seurat:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Input</strong>: You can directly use Seurat’s
<code>FindAllMarkers()</code> output as input</p></li>
<li><p><strong>Output</strong>: Annotation results can be easily added
to your Seurat object:</p></li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>seurat_obj<span class="sc">$</span>cell_type_consensus <span class="ot">&lt;-</span> plyr<span class="sc">::</span><span class="fu">mapvalues</span>(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>  <span class="at">x =</span> <span class="fu">as.character</span>(<span class="fu">Idents</span>(seurat_obj)),</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  <span class="at">from =</span> <span class="fu">names</span>(consensus_results<span class="sc">$</span>final_annotations),</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="at">to =</span> consensus_results<span class="sc">$</span>final_annotations</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>)</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Visualization</strong>: Use Seurat’s visualization functions
with the added annotations:</li>
</ol>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">DimPlot</span>(seurat_obj, <span class="at">group.by =</span> <span class="st">&quot;cell_type_consensus&quot;</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="can-i-use-mllmcelltype-with-scanpyanndata-in-r" class="section level3">
<h3>Can I use mLLMCelltype with Scanpy/AnnData in R?</h3>
<p>Yes, you can use mLLMCelltype with Scanpy/AnnData objects in R:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Extract marker genes</strong>: Export marker genes from
your Scanpy analysis to a CSV file</p></li>
<li><p><strong>Run mLLMCelltype</strong>: Use the CSV file as input to
mLLMCelltype</p></li>
<li><p><strong>Import results</strong>: Add the annotation results back
to your AnnData object</p></li>
</ol>
<p>Alternatively, you can use the Python version of mLLMCelltype for
direct integration with Scanpy.</p>
</div>
<div id="how-can-i-combine-mllmcelltype-with-traditional-annotation-methods" class="section level3">
<h3>How can I combine mLLMCelltype with traditional annotation
methods?</h3>
<p>mLLMCelltype can be used alongside traditional annotation
methods:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Complementary approach</strong>: Use both methods and
compare results</p></li>
<li><p><strong>Validation</strong>: Use mLLMCelltype to validate
annotations from reference-based methods</p></li>
<li><p><strong>Hybrid approach</strong>: Use reference-based methods for
well-characterized cell types and mLLMCelltype for novel or rare cell
types</p></li>
<li><p><strong>Ensemble method</strong>: Create a consensus between
mLLMCelltype and traditional methods</p></li>
</ol>
</div>
</div>
<div id="advanced-usage" class="section level2">
<h2>Advanced Usage</h2>
<div id="how-can-i-customize-the-prompts-used-by-mllmcelltype" class="section level3">
<h3>How can I customize the prompts used by mLLMCelltype?</h3>
<p>While mLLMCelltype uses carefully designed prompts, advanced users
can customize them:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Create a custom annotation prompt</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>custom_prompt <span class="ot">&lt;-</span> <span class="fu">create_annotation_prompt</span>(</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>  <span class="at">marker_data =</span> your_markers,</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>  <span class="at">tissue_name =</span> <span class="st">&quot;your_tissue&quot;</span>,</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>  <span class="at">top_gene_count =</span> <span class="dv">10</span>,</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>  <span class="at">custom_instructions =</span> <span class="st">&quot;Also consider developmental stage and activation state.&quot;</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="co"># Use the custom prompt directly</span></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>response <span class="ot">&lt;-</span> <span class="fu">get_model_response</span>(</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>  <span class="at">prompt =</span> custom_prompt,</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">&quot;claude-sonnet-4-5-20250929&quot;</span>,</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>  <span class="at">api_key =</span> your_api_key</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="can-i-add-my-own-custom-llm-models" class="section level3">
<h3>Can I add my own custom LLM models?</h3>
<p>Yes, you can register custom models and providers:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Register a custom provider</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="fu">register_custom_provider</span>(</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>  <span class="at">provider_name =</span> <span class="st">&quot;my_provider&quot;</span>,</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>  <span class="at">api_url =</span> <span class="st">&quot;https://api.my-provider.com/v1/chat/completions&quot;</span>,</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>  <span class="at">api_key_env_var =</span> <span class="st">&quot;MY_PROVIDER_API_KEY&quot;</span>,</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>  <span class="at">process_function =</span> <span class="cf">function</span>(prompt, api_key) {</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    <span class="co"># Custom implementation</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>  }</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co"># Register a custom model</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="fu">register_custom_model</span>(</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>  <span class="at">model_name =</span> <span class="st">&quot;my-custom-model&quot;</span>,</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>  <span class="at">provider =</span> <span class="st">&quot;my_provider&quot;</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a><span class="co"># Use the custom model</span></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">annotate_cell_types</span>(</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>  <span class="at">input =</span> your_markers,</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>  <span class="at">tissue_name =</span> <span class="st">&quot;your_tissue&quot;</span>,</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>  <span class="at">model =</span> <span class="st">&quot;my-custom-model&quot;</span>,</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>  <span class="at">api_key =</span> your_api_key</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="how-can-i-contribute-to-mllmcelltype" class="section level3">
<h3>How can I contribute to mLLMCelltype?</h3>
<p>We welcome contributions! Here are some ways to contribute:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Report issues</strong>: Report bugs or suggest features
on our <a href="https://github.com/cafferychen777/mLLMCelltype/issues">GitHub
repository</a></p></li>
<li><p><strong>Improve documentation</strong>: Help us improve
documentation and examples</p></li>
<li><p><strong>Add new models</strong>: Implement support for new LLM
models</p></li>
<li><p><strong>Share benchmarks</strong>: Share your benchmarking
results with different tissues and species</p></li>
<li><p><strong>Develop new features</strong>: Contribute code for new
features or improvements</p></li>
</ol>
<p>See our <a href="https://cafferyang.com/mLLMCelltype/articles/contributing-guide.html">Contributing
Guide</a> for more details.</p>
</div>
</div>
<div id="next-steps" class="section level2">
<h2>Next Steps</h2>
<p>Now that you have answers to common questions, you can explore:</p>
<ul>
<li><a href="https://cafferyang.com/mLLMCelltype/articles/advanced-features.html">Advanced
Features</a>: Learn about hierarchical annotation and other advanced
features</li>
<li><a href="https://cafferyang.com/mLLMCelltype/articles/contributing-guide.html">Contributing
Guide</a>: Find out how to contribute to the project</li>
<li><a href="https://cafferyang.com/mLLMCelltype/articles/version-history.html">Version
History</a>: Review the development history of mLLMCelltype</li>
</ul>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
